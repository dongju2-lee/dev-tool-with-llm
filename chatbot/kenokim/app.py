import streamlit as st
import os
import sys
import uuid
from dotenv import load_dotenv
from api.client import MCPClient

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# ì´ì œ ìƒëŒ€ ê²½ë¡œë¡œ ì„í¬íŠ¸
from langchain_gemini_mcp_client import GeminiMCPClient

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìŠ¬ë¼ì„ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="centered"
)

# CSS ì¶”ê°€
st.markdown("""
<style>
    .stChatMessage {
        padding: 10px;
        border-radius: 10px;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("ìŠ¬ë¼ì„ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# ì„¸ì…˜ì— LangGraph MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if "mcp_react_client" not in st.session_state:
    st.session_state.mcp_react_client = None

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    # Gemini ëª¨ë¸ ì„ íƒ
    model_options = {
        "gemini-2.0-flash": "Gemini Flash"
    }
    selected_model = st.selectbox(
        "Gemini ëª¨ë¸",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x],
        index=0,
        help="ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ì‘ë‹µ ìƒì„± ë°©ì‹ ì„ íƒ
    response_type = st.radio(
        "ì‘ë‹µ ìƒì„± ë°©ì‹",
        ["MCP ì„œë²„", "MCP_REACT (LangGraph)"]
    )

# MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” - ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©
try:
    mcp_client = MCPClient(model_name=selected_model)
    st.sidebar.success(f"Vertex AI ì—°ê²° ì„±ê³µ (ëª¨ë¸: {model_options[selected_model]})")
except Exception as e:
    st.sidebar.error(f"Vertex AI ì—°ê²° ì˜¤ë¥˜: {str(e)}")
    st.sidebar.warning("í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš” (VERTEX_API_KEY, GCP_PROJECT_ID)")
    mcp_client = None

# LangGraph MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if response_type == "MCP_REACT (LangGraph)" and st.session_state.mcp_react_client is None:
    try:
        with st.sidebar:
            with st.spinner("LangGraph MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘..."):
                # ìƒˆë¡œìš´ ì´ˆê¸°í™” ë°©ì‹ìœ¼ë¡œ ë³€ê²½
                st.session_state.mcp_react_client = GeminiMCPClient(
                    model_name=selected_model,
                    # í•„ìš”ì‹œ API í‚¤ ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
                    # api_key="YOUR_API_KEY"
                )
                st.session_state.mcp_react_client.initialize()
                st.success("LangGraph MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        st.sidebar.error(f"LangGraph MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        st.session_state.mcp_react_client = None

# ì„œë²„ ìƒíƒœ í™•ì¸ ë²„íŠ¼
with st.sidebar:
    if st.button("ì„œë²„ ìƒíƒœ í™•ì¸"):
        if response_type == "MCP_REACT (LangGraph)" and st.session_state.mcp_react_client:
            try:
                status = st.session_state.mcp_react_client.check_connection()
                st.success(f"LangGraph MCP ì„œë²„ ìƒíƒœ: {status['status']}, ëª¨ë¸: {status.get('model', 'N/A')}")
                if status['status'] == 'online':
                    st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {', '.join(status.get('available_tools', []))}")
            except Exception as e:
                st.error(f"LangGraph MCP ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        elif mcp_client:
            try:
                status = mcp_client.check_connection()
                st.success(f"MCP ì„œë²„ ìƒíƒœ: {status['status']}, ëª¨ë¸: {status.get('model', 'N/A')}")
            except Exception as e:
                st.error(f"MCP ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
                # ì—°ê²° ì˜¤ë¥˜ ì‹œ ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜
                response_type = "ê¸°ë³¸ (ëœë¤)"
        else:
            st.error("í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
    
    # ë„êµ¬ ëª©ë¡ í‘œì‹œ ì˜ì—­
    st.subheader("ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬")
    if st.button("ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"):
        if response_type == "MCP_REACT (LangGraph)" and st.session_state.mcp_react_client:
            try:
                with st.spinner("ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    tools = st.session_state.mcp_react_client.get_tools()
                    if tools:
                        st.success(f"{len(tools)}ê°œì˜ ë„êµ¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")
                        for tool in tools:
                            with st.expander(f"ğŸ”§ {tool['name']}"):
                                st.write(tool.get('description', 'ì„¤ëª… ì—†ìŒ'))
                    else:
                        st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            except Exception as e:
                st.error(f"ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.thread_id = str(uuid.uuid4())
        st.experimental_rerun()

# ëŒ€í™” ì´ë ¥ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í‘œì‹œ
        if "type" not in message or message["type"] == "text":
            st.markdown(message["content"])
        # ì´ë¯¸ì§€ ë©”ì‹œì§€ í‘œì‹œ
        elif message["type"] == "image":
            if "text" in message:
                st.markdown(message["text"])
            st.image(message["content"], caption=message.get("caption", ""), use_column_width=True)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            if response_type == "MCP ì„œë²„" and mcp_client:
                try:
                    # MCP ì„œë²„ë¡œ ë©”ì‹œì§€ ì „ì†¡
                    response_data = mcp_client.process_query(
                        query=prompt,
                        history=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages[:-1] if "type" not in m or m["type"] == "text"]
                    )
                    
                    # ì‘ë‹µ ì¶”ì¶œ
                    response_content = response_data.get("response", "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    
                    # ì‘ë‹µ í‘œì‹œ
                    st.markdown(response_content)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant",
                        "type": "text",
                        "content": response_content
                    })
                except Exception as e:
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²´ ì‘ë‹µ ì‚¬ìš©
                    response_content = f"MCP ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}"
                    st.markdown(response_content)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant",
                        "type": "text",
                        "content": response_content
                    })
            elif response_type == "MCP_REACT (LangGraph)" and st.session_state.mcp_react_client:
                try:
                    # ëŒ€í™” ì´ë ¥ ì¶”ì¶œ
                    history = [{"role": m["role"], "content": m["content"]} 
                              for m in st.session_state.messages[:-1] 
                              if "type" not in m or m["type"] == "text"]
                    
                    # LangGraph MCP ReAct ì—ì´ì „íŠ¸ë¡œ ë©”ì‹œì§€ ì „ì†¡
                    response_data = st.session_state.mcp_react_client.process_query(
                        query=prompt,
                        history=history,
                        thread_id=st.session_state.thread_id
                    )
                    
                    # ì‘ë‹µ ì¶”ì¶œ
                    response_content = response_data.get("response", "ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    
                    # ë„êµ¬ ì¶œë ¥ ì •ë³´ ì¶”ê°€
                    tool_outputs = response_data.get("tool_outputs", [])
                    if tool_outputs:
                        tool_info = "\n\n**ë„êµ¬ ì‚¬ìš© ì •ë³´:**\n"
                        for tool_output in tool_outputs:
                            tool_info += f"- **{tool_output.get('tool', 'ì•Œ ìˆ˜ ì—†ìŒ')}**: {tool_output.get('result', '')}\n"
                        response_content += tool_info
                    
                    # ì‘ë‹µ í‘œì‹œ
                    st.markdown(response_content)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant",
                        "type": "text",
                        "content": response_content
                    })
                except Exception as e:
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²´ ì‘ë‹µ ì‚¬ìš©
                    response_content = f"LangGraph MCP ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                    st.markdown(response_content)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant",
                        "type": "text",
                        "content": response_content
                    })
            else:
                # ì‘ë‹µ ìƒì„± ë°©ì‹ì´ ì—†ê±°ë‚˜ í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
                response_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì„ íƒí•œ ì‘ë‹µ ìƒì„± ë°©ì‹ì— ëŒ€í•œ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                st.markdown(response_content)
                
                # ì„¸ì…˜ì— ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "type": "text",
                    "content": response_content
                }) 