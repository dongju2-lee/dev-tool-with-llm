"""
ê³ ê¸‰ Supervisor: LangGraphë¥¼ ì‚¬ìš©í•œ ì§ì ‘ êµ¬í˜„
"""

import logging
from typing import Annotated, Literal, TypedDict
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END

from .grafana_mcp_agent import make_grafana_agent
from .grafana_renderer_mcp_agent import make_grafana_renderer_agent
from ...core.config import settings
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

# State ì •ì˜
class SupervisorState(TypedDict):
    messages: Annotated[list[BaseMessage], "The messages in the conversation"]
    next: Annotated[str, "The next agent to route to"]

# init LLM
llm = ChatGoogleGenerativeAI(
    model=settings.gemini_model,
    google_api_key=settings.gemini_api_key,
    temperature=0
)

# Agent ë©”íƒ€ë°ì´í„° - ì‹¤ì œ Agent ìƒì„±ê³¼ ì—°ë™
AGENT_METADATA = {
    "grafana_agent": {
        "factory": make_grafana_agent,
        "description": "Grafana ë°ì´í„° ë¶„ì„, ë©”íŠ¸ë¦­ ì¡°íšŒ, ëª¨ë‹ˆí„°ë§ ì •ë³´ ì œê³µ ì „ë¬¸ê°€",
        "keywords": ["ë¶„ì„", "ë©”íŠ¸ë¦­", "ì„±ëŠ¥", "ìƒíƒœ", "í™•ì¸", "ì¡°íšŒ", "ë¡œê·¸"],
        "use_cases": [
            "CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ë¶„ì„",
            "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ë¶„ì„",
            "ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§",
            "ë¡œê·¸ íŒ¨í„´ ë¶„ì„"
        ]
    },
    "grafana_renderer_mcp_agent": {
        "factory": make_grafana_renderer_agent,
        "description": "Grafana ëŒ€ì‹œë³´ë“œ ì‹œê°í™” ë° ë Œë”ë§ ì „ë¬¸ê°€",
        "keywords": ["ë Œë”ë§", "ë Œë”", "ë³´ì—¬ì¤˜", "ì‹œê°í™”", "ì°¨íŠ¸", "ëŒ€ì‹œë³´ë“œ", "ìŠ¤í¬ë¦°ìƒ·", "ì´ë¯¸ì§€", "ëª©ë¡", "ê·¸ë ¤ì¤˜", "ê·¸ë¦¼"],
        "use_cases": [
            "ëŒ€ì‹œë³´ë“œ ë Œë”ë§ ë° ì´ë¯¸ì§€ ìƒì„±",
            "ëŒ€ì‹œë³´ë“œ ëª©ë¡ ì¡°íšŒ",
            "ì°¨íŠ¸ ë° ê·¸ë˜í”„ ìº¡ì²˜", 
            "ëŒ€ì‹œë³´ë“œ ìŠ¤í¬ë¦°ìƒ· ìƒì„±",
            "ì‹œê°í™” ë¦¬í¬íŠ¸ ìƒì„±"
        ]
    }
}

# Supervisor ë…¸ë“œ í•¨ìˆ˜
def supervisor_node(state: SupervisorState) -> SupervisorState:
    """Supervisorê°€ ë‹¤ìŒ agentë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    messages = state["messages"]
    
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    last_message = messages[-1] if messages else None
    if not last_message or not hasattr(last_message, 'content'):
        return {"messages": messages, "next": "END"}
    
    content = last_message.content.lower()
    
    # ê°„ë‹¨í•œ ë¼ìš°íŒ… ë¡œì§
    if any(keyword in content for keyword in ["ëŒ€ì‹œë³´ë“œ", "ëª©ë¡", "ë Œë”ë§", "ë Œë”", "ë³´ì—¬ì¤˜", "ì‹œê°í™”", "ì°¨íŠ¸", "ìŠ¤í¬ë¦°ìƒ·", "ì´ë¯¸ì§€", "ê·¸ë ¤ì¤˜"]):
        next_agent = "grafana_renderer_mcp_agent"
    elif any(keyword in content for keyword in ["ë¶„ì„", "ì„±ëŠ¥", "ìƒíƒœ", "í™•ì¸", "ë©”íŠ¸ë¦­", "ë©”ëª¨ë¦¬", "cpu", "ë””ìŠ¤í¬", "ì‚¬ìš©ëŸ‰", "ëª¨ë‹ˆí„°ë§"]):
        next_agent = "grafana_agent"
    else:
        # ì¼ë°˜ì ì¸ ìš”ì²­ì€ ì§ì ‘ ì‘ë‹µ
        supervisor_prompt = generate_dynamic_supervisor_prompt(AGENT_METADATA)
        response = llm.invoke([
            {"role": "system", "content": supervisor_prompt},
            {"role": "user", "content": last_message.content}
        ])
        
        new_message = AIMessage(content=response.content, name="supervisor")
        return {"messages": messages + [new_message], "next": "END"}
    
    return {"messages": messages, "next": next_agent}

def router(state: SupervisorState) -> Literal["grafana_agent", "grafana_renderer_mcp_agent", "END"]:
    """ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
    return state["next"]

def generate_dynamic_supervisor_prompt(agent_metadata: dict) -> str:
    """Agent ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  Supervisor í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    return f"""
ë‹¹ì‹ ì€ Grafana ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì˜ Supervisorì…ë‹ˆë‹¤. 
ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì „ë¬¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ì „ë‹¬í•œ í›„, ê·¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì œëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”.

**í•µì‹¬ ì±…ì„**:
1. ìš”ì²­ ë¶„ì„ ë° ì ì ˆí•œ ì—ì´ì „íŠ¸ ì„ íƒ
2. ì „ë¬¸ ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì™„ì „íˆ ì „ë‹¬
3. êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ì‘ë‹µ ë³´ì¥

**ì „ë¬¸ ì—ì´ì „íŠ¸ ì„ íƒ ê¸°ì¤€**:

ğŸ¨ **grafana_renderer_mcp_agent** ì‚¬ìš© ì‹œ:
- "ëŒ€ì‹œë³´ë“œ", "ëª©ë¡", "ë Œë”ë§", "ë Œë”", "ë³´ì—¬ì¤˜", "ì‹œê°í™”"  
- êµ¬ì²´ì  ëŒ€ì‹œë³´ë“œ ì´ë¦„ (Node Exporter, Prometheus Stats ë“±)
- "ì´ë¯¸ì§€", "ì°¨íŠ¸", "ìŠ¤í¬ë¦°ìƒ·" ê´€ë ¨

ğŸ“Š **grafana_agent** ì‚¬ìš© ì‹œ:
- "ë¶„ì„", "ì„±ëŠ¥", "ìƒíƒœ", "í™•ì¸", "ë©”íŠ¸ë¦­"
- "ë©”ëª¨ë¦¬", "CPU", "ë””ìŠ¤í¬", "ì‚¬ìš©ëŸ‰"
- "ëª¨ë‹ˆí„°ë§", "ë¡œê·¸", "íŒ¨í„´" ê´€ë ¨

**ê²°ê³¼ ì „ë‹¬ ì›ì¹™**:
âœ… **í•´ì•¼ í•  ì¼**:
- ì „ë¬¸ ì—ì´ì „íŠ¸ì˜ ì™„ì „í•œ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
- êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ëª©ë¡ì´ ìˆìœ¼ë©´ ëª¨ë‘ í¬í•¨
- ì‚¬ìš©ìê°€ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ

âŒ **í•˜ì§€ ë§ì•„ì•¼ í•  ì¼**:
- "ì „ë‹¬í–ˆìŠµë‹ˆë‹¤"ë§Œ ì‘ë‹µ
- "ì²˜ë¦¬ ì™„ë£Œ"ë§Œ ì‘ë‹µ
- ì „ë¬¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ìš”ì•½í•˜ê±°ë‚˜ ìƒëµ
- ì¶”ìƒì ì´ê±°ë‚˜ ëª¨í˜¸í•œ ì‘ë‹µ

**ì‘ë‹µ ë°©ì‹**:
- **ì¼ë°˜ ì¸ì‚¬**: ì§ì ‘ ì¹œê·¼í•˜ê²Œ ì‘ë‹µ
- **ë„ì›€ ìš”ì²­**: ê¸°ëŠ¥ ëª©ë¡ ê°„ë‹¨íˆ ì•ˆë‚´
- **Grafana ìš”ì²­**: ì „ë¬¸ ì—ì´ì „íŠ¸ í˜¸ì¶œ â†’ ì™„ì „í•œ ê²°ê³¼ ì „ë‹¬

**ì„±ê³µì ì¸ ì‘ë‹µ ì˜ˆì‹œ**:
ì‚¬ìš©ì: "ëŒ€ì‹œë³´ë“œ ëª©ë¡ ë³´ì—¬ì¤˜"
â†’ grafana_renderer_mcp_agent í˜¸ì¶œ
â†’ ì—ì´ì „íŠ¸ ê²°ê³¼: "í˜„ì¬ 7ê°œ ëŒ€ì‹œë³´ë“œ... (ìƒì„¸ ëª©ë¡)"
â†’ ì‚¬ìš©ìì—ê²Œ ê·¸ëŒ€ë¡œ ì „ë‹¬

**ì‹¤íŒ¨í•˜ëŠ” ì‘ë‹µ ì˜ˆì‹œ**:
- "ëŒ€ì‹œë³´ë“œ ëª©ë¡ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤" âŒ
- "ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤" âŒ
- "ì•Œê² ìŠµë‹ˆë‹¤" âŒ
- "ìš”ì•½í•´ ë“œë ¸ìŠµë‹ˆë‹¤" âŒ

âš ï¸ **ì¶”ê°€ ê·œì¹™**:
- ë§Œì•½ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ë¹ˆì•½í•œ ì‘ë‹µì„ í–ˆë‹¤ë©´, ë‹¤ì‹œ ì „ë‹¬í•˜ì—¬ êµ¬ì²´ì ì¸ ê²°ê³¼ë¥¼ ìš”ì²­í•˜ì„¸ìš”
- ì „ë¬¸ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µì— ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ìš”ì²­í•´ ì£¼ì„¸ìš”"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”
- ì ˆëŒ€ "ì•Œê² ìŠµë‹ˆë‹¤", "ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤" ê°™ì€ ë¹ˆì•½í•œ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”

ë‹¤ë¥¸ agentì—ê²Œ ëª…ë ¹ì„ ì „ë‹¬í•œ ê²½ìš°, ë°˜ë“œì‹œ ì‚¬ìš©ìì—ê²ŒëŠ” agentê°€ ë°˜í™˜í•œ ê²°ê³¼ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. 
ë°˜ë“œì‹œ, "...ì—ê²Œ ì „ë‹¬í•˜ì—¬ ë¶„ì„í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ëŠ” ëŒ€ë¡œ ì¦‰ì‹œ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤." ì´ëŸ° ì‘ë‹µì€ í•˜ì§€ ë§ˆì„¸ìš”.
agent ì˜ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ì œê³µí•œ êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©ìì—ê²Œ ì™„ì „íˆ ì „ë‹¬í•˜ì„¸ìš”.
ê³¼ê±°ì˜ chat history ì— í•„ìš”í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.
"""



async def create_enhanced_supervisor_graph():
    """í–¥ìƒëœ Supervisor ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # 1. ì—ì´ì „íŠ¸ë“¤ ìƒì„±
        grafana_agent = await make_grafana_agent(llm)
        grafana_renderer_agent = await make_grafana_renderer_agent(llm)
        
        # 2. StateGraph ìƒì„±
        workflow = StateGraph(SupervisorState)
        
        # 3. ë…¸ë“œ ì¶”ê°€
        workflow.add_node("supervisor", supervisor_node)
        workflow.add_node("grafana_agent", grafana_agent)
        workflow.add_node("grafana_renderer_mcp_agent", grafana_renderer_agent)
        
        # 4. ì—£ì§€ ì¶”ê°€
        workflow.add_edge(START, "supervisor")
        workflow.add_conditional_edges(
            "supervisor",
            router,
            {
                "grafana_agent": "grafana_agent",
                "grafana_renderer_mcp_agent": "grafana_renderer_mcp_agent",
                "END": END
            }
        )
        workflow.add_edge("grafana_agent", END)
        workflow.add_edge("grafana_renderer_mcp_agent", END)
        
        logger.info("Enhanced supervisor graph created successfully")
        return workflow.compile()
        
    except Exception as e:
        logger.error(f"Error creating enhanced supervisor graph: {e}")
        raise

# ì „ì—­ ë³€ìˆ˜ë¡œ supervisor_graph ì €ì¥
_enhanced_supervisor_graph = None

async def get_enhanced_supervisor_graph():
    """í–¥ìƒëœ supervisor_graphë¥¼ lazy loadingìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    global _enhanced_supervisor_graph
    if _enhanced_supervisor_graph is None:
        _enhanced_supervisor_graph = await create_enhanced_supervisor_graph()
    return _enhanced_supervisor_graph 