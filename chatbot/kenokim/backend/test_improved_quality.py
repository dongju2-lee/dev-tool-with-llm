#!/usr/bin/env python3
"""
ì‘ë‹µ í’ˆì§ˆ ê°œì„  í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
from app.graph.instance import process_chat_message

# í’ˆì§ˆ ê°œì„ ì„ í™•ì¸í•  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
QUALITY_TEST_CASES = [
    {
        "name": "dashboard_list_basic",
        "request": "ëŒ€ì‹œë³´ë“œ ëª©ë¡ ë³´ì—¬ì¤˜",
        "expected_improvements": [
            "ì‹¤ì œ ëŒ€ì‹œë³´ë“œ ëª©ë¡ í¬í•¨",
            "êµ¬ì²´ì ì¸ ëŒ€ì‹œë³´ë“œ ì´ë¦„ë“¤",
            "ì„ íƒ ê°€ëŠ¥í•œ ì˜µì…˜ ì œê³µ"
        ]
    },
    {
        "name": "dashboard_render_specific",
        "request": "Node Exporter ëŒ€ì‹œë³´ë“œ ë Œë”ë§í•´ì¤˜",
        "expected_improvements": [
            "ë Œë”ë§ ì‹œë„ ê²°ê³¼",
            "ì‹œê°„ ë²”ìœ„ ì •ë³´",
            "êµ¬ì²´ì ì¸ ìƒíƒœ ë©”ì‹œì§€"
        ]
    },
    {
        "name": "performance_analysis",
        "request": "ì„œë²„ ì„±ëŠ¥ ë¶„ì„í•´ì¤˜",
        "expected_improvements": [
            "ì‹¤ì œ ë©”íŠ¸ë¦­ ìˆ˜ì¹˜",
            "êµ¬ì²´ì ì¸ ë¶„ì„ ê²°ê³¼",
            "ì •ìƒ/ë¹„ì •ìƒ íŒë‹¨"
        ]
    },
    {
        "name": "memory_check",
        "request": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸í•´ì¤˜",
        "expected_improvements": [
            "ì‹¤ì œ ë©”ëª¨ë¦¬ ìˆ˜ì¹˜",
            "ì‚¬ìš©ë¥  ë°±ë¶„ìœ¨",
            "ìš©ëŸ‰ ì •ë³´"
        ]
    },
    {
        "name": "ambiguous_request",
        "request": "ì‹œìŠ¤í…œ ìƒíƒœ ì•Œë ¤ì¤˜",
        "expected_improvements": [
            "êµ¬ì²´ì ì¸ ë©”íŠ¸ë¦­ë“¤",
            "ì—¬ëŸ¬ ì§€í‘œ í¬í•¨",
            "ì¢…í•©ì ì¸ ìƒíƒœ í‰ê°€"
        ]
    }
]

def analyze_response_quality(response: str, tools_used: list, agent_used: str) -> dict:
    """ì‘ë‹µ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    # ë¶€ì •ì  íŒ¨í„´ (ë¹ˆì•½í•œ ì‘ë‹µ)
    poor_patterns = [
        "ì•Œê² ìŠµë‹ˆë‹¤",
        "ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤", 
        "ì „ë‹¬í–ˆìŠµë‹ˆë‹¤",
        "ì™„ë£Œí–ˆìŠµë‹ˆë‹¤",
        "í™•ì¸í–ˆìŠµë‹ˆë‹¤"
    ]
    
    # ê¸ì •ì  íŒ¨í„´ (ì¢‹ì€ ì‘ë‹µ)
    good_patterns = [
        "í˜„ì¬",
        "ê²°ê³¼",
        "ë¶„ì„",
        "ìƒíƒœ",
        "%",
        "GB",
        "MB",
        "ëŒ€ì‹œë³´ë“œ",
        "ë©”íŠ¸ë¦­"
    ]
    
    analysis = {
        "length": len(response),
        "has_poor_patterns": any(pattern in response for pattern in poor_patterns),
        "has_good_patterns": any(pattern in response for pattern in good_patterns),
        "tools_used_count": len(tools_used),
        "agent_used": agent_used,
        "has_specific_data": any(char in response for char in ['%', 'GB', 'MB', ':', '/']),
        "quality_score": 0
    }
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    score = 0
    
    # ì‘ë‹µ ê¸¸ì´ (50ì ì´ìƒì´ë©´ ì¢‹ìŒ)
    if analysis["length"] >= 50:
        score += 20
    elif analysis["length"] >= 20:
        score += 10
    
    # ë¹ˆì•½í•œ íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì¢‹ìŒ
    if not analysis["has_poor_patterns"]:
        score += 20
    
    # ì¢‹ì€ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì¢‹ìŒ
    if analysis["has_good_patterns"]:
        score += 20
    
    # ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆìœ¼ë©´ ì¢‹ìŒ
    if analysis["tools_used_count"] > 0:
        score += 20
    
    # êµ¬ì²´ì ì¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¢‹ìŒ
    if analysis["has_specific_data"]:
        score += 20
    
    analysis["quality_score"] = score
    
    return analysis

async def run_quality_tests():
    """í’ˆì§ˆ ê°œì„  í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    
    print("ğŸ”¬ ì‘ë‹µ í’ˆì§ˆ ê°œì„  í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    total_score = 0
    test_count = len(QUALITY_TEST_CASES)
    
    for i, test_case in enumerate(QUALITY_TEST_CASES, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}/{test_count}: {test_case['name']}")
        print(f"ğŸ“ ìš”ì²­: {test_case['request']}")
        
        try:
            # ìš”ì²­ ì²˜ë¦¬
            result = await process_chat_message(test_case["request"])
            
            # ì‘ë‹µ ë¶„ì„
            analysis = analyze_response_quality(
                result["content"],
                result["tools_used"],
                result["agent_used"]
            )
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"ğŸ¤– Agent: {result['agent_used']}")
            print(f"ğŸ”§ Tools: {', '.join(result['tools_used']) if result['tools_used'] else 'None'}")
            print(f"ğŸ“ ì‘ë‹µ ê¸¸ì´: {analysis['length']}ì")
            print(f"â­ í’ˆì§ˆ ì ìˆ˜: {analysis['quality_score']}/100")
            
            # ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 200ìë§Œ)
            display_content = result["content"][:200]
            if len(result["content"]) > 200:
                display_content += "..."
            print(f"ğŸ’¬ ì‘ë‹µ: {display_content}")
            
            # í’ˆì§ˆ ë¶„ì„ ìƒì„¸
            print(f"ğŸ“Š ë¶„ì„:")
            print(f"  - ë¹ˆì•½í•œ íŒ¨í„´: {'âŒ ë°œê²¬ë¨' if analysis['has_poor_patterns'] else 'âœ… ì—†ìŒ'}")
            print(f"  - ì¢‹ì€ íŒ¨í„´: {'âœ… ìˆìŒ' if analysis['has_good_patterns'] else 'âŒ ì—†ìŒ'}")
            print(f"  - êµ¬ì²´ì  ë°ì´í„°: {'âœ… ìˆìŒ' if analysis['has_specific_data'] else 'âŒ ì—†ìŒ'}")
            
            total_score += analysis['quality_score']
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")
            
        print("-" * 60)
    
    # ì „ì²´ ê²°ê³¼
    average_score = total_score / test_count if test_count > 0 else 0
    print(f"\nğŸ ì „ì²´ ê²°ê³¼")
    print(f"ğŸ“Š í‰ê·  í’ˆì§ˆ ì ìˆ˜: {average_score:.1f}/100")
    
    if average_score >= 80:
        print("ğŸ‰ ì‘ë‹µ í’ˆì§ˆ: ìš°ìˆ˜")
    elif average_score >= 60:
        print("ğŸ‘ ì‘ë‹µ í’ˆì§ˆ: ì–‘í˜¸")
    elif average_score >= 40:
        print("ğŸ“ˆ ì‘ë‹µ í’ˆì§ˆ: ê°œì„  í•„ìš”")
    else:
        print("ğŸ”§ ì‘ë‹µ í’ˆì§ˆ: ëŒ€í­ ê°œì„  í•„ìš”")

if __name__ == "__main__":
    asyncio.run(run_quality_tests()) 