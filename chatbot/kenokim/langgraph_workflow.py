"""LangGraph ê¸°ë°˜ ì±—ë´‡ ì›Œí¬í”Œë¡œìš°

ì´ ëª¨ë“ˆì€ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ê¸°ë°˜ì˜ ëŒ€í™”í˜• ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import os
from typing import Dict, List, Any, TypedDict, Optional, Union, Callable
from langgraph.graph import StateGraph, END
from api.client import VertexAIClient
from PIL import Image
import io

# ìƒíƒœ íƒ€ì… ì •ì˜
class ChatState(TypedDict):
    """ì±—ë´‡ ìƒíƒœ íƒ€ì… ì •ì˜"""
    messages: List[Dict[str, Any]]  # ì±„íŒ… ì´ë ¥
    current_input: str              # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
    response: str                   # í˜„ì¬ ì‘ë‹µ
    dashboard_mode: bool            # ëŒ€ì‹œë³´ë“œ ëª¨ë“œ ì—¬ë¶€
    error: str                      # ì˜¤ë¥˜ ë©”ì‹œì§€
    images: List[Dict[str, Any]]    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸

# ì „ì—­ ë³€ìˆ˜ - API í´ë¼ì´ì–¸íŠ¸
client = VertexAIClient()

def create_initial_state() -> ChatState:
    """ì´ˆê¸° ìƒíƒœ ìƒì„± í•¨ìˆ˜"""
    return {
        "messages": [],
        "current_input": "",
        "response": "",
        "dashboard_mode": False,
        "error": "",
        "images": []
    }

# strangekino.png ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_strangekino_image() -> bytes:
    """strangekino.png ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ìœ„ì¹˜ í™•ì¸
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # ì´ë¯¸ì§€ ê²½ë¡œ ì§€ì •
    image_path = os.path.join(current_dir, "strangekino.png")
    
    try:
        # ì´ë¯¸ì§€ íŒŒì¼ ì—´ê¸°
        with open(image_path, "rb") as f:
            return f.read()
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜
        img = Image.new('RGB', (100, 100), color=(255, 0, 0))
        img_bytes = io.BytesIO()
        img.save(img_bytes, format="PNG")
        img_bytes.seek(0)
        return img_bytes.getvalue()

# ì›Œí¬í”Œë¡œìš° ë…¸ë“œ í•¨ìˆ˜ë“¤
def process_input(state: ChatState) -> Dict:
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ëª¨ë“œ ê²°ì •"""
    try:
        # í˜„ì¬ ì…ë ¥ì—ì„œ ëŒ€ì‹œë³´ë“œ í‚¤ì›Œë“œ ê°ì§€
        is_dashboard_request = any(
            keyword in state["current_input"].lower() 
            for keyword in ["ëŒ€ì‹œë³´ë“œ", "ì°¨íŠ¸", "ê·¸ë˜í”„", "ë³´ì—¬ì¤˜"]
        )
        
        # ë©”ì‹œì§€ ì´ë ¥ ì—…ë°ì´íŠ¸
        messages = state["messages"].copy()
        messages.append({"role": "user", "content": state["current_input"]})
        
        return {
            "messages": messages,
            "dashboard_mode": is_dashboard_request
        }
    except Exception as e:
        return {"error": f"ì…ë ¥ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"}

def generate_llm_response(state: ChatState) -> Dict:
    """Gemini ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±"""
    try:
        # ëª¨ë¸ í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ ì¤€ë¹„
        messages = [
            {"role": msg["role"], "content": msg["content"]} 
            for msg in state["messages"] 
            if "role" in msg and "content" in msg
        ]
        
        # API í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±
        response = client.chat(messages)
        
        if response["status"] == "success":
            return {"response": response["content"]}
        else:
            return {"error": response.get("error_message", "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨")}
            
    except Exception as e:
        return {"error": f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}"}

def update_messages(state: ChatState) -> Dict:
    """ë©”ì‹œì§€ ì´ë ¥ ì—…ë°ì´íŠ¸"""
    messages = state["messages"].copy()
    messages.append({"role": "assistant", "content": state["response"]})
    return {"messages": messages}

def create_dashboard_response(state: ChatState) -> Dict:
    """ëŒ€ì‹œë³´ë“œ ì‘ë‹µ ìƒì„±"""
    
    # strangekino.png ì´ë¯¸ì§€ ë¡œë“œ
    image_data = load_strangekino_image()
    
    # ì‘ë‹µ ë©”ì‹œì§€
    response = "ì—¬ê¸° ìŠ¤íŠ¸ë ˆì¸ì§€ í‚¤ë…¸ ì´ë¯¸ì§€ì…ë‹ˆë‹¤! ğŸŒŸ"
    
    # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
    messages = state["messages"].copy()
    messages.append({
        "role": "assistant", 
        "content": response,
        "is_dashboard": True
    })
    
    # ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
    images = state.get("images", []).copy()
    images.append({
        "data": image_data,
        "caption": "ìŠ¤íŠ¸ë ˆì¸ì§€ í‚¤ë…¸",
        "message_index": len(messages) - 1  # ì—°ê²°ëœ ë©”ì‹œì§€ ì¸ë±ìŠ¤
    })
    
    return {
        "messages": messages, 
        "response": response,
        "images": images
    }

def handle_error(state: ChatState) -> Dict:
    """ì˜¤ë¥˜ ì²˜ë¦¬"""
    error_message = state.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}"
    
    # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
    messages = state["messages"].copy()
    messages.append({"role": "assistant", "content": response})
    
    return {"messages": messages, "response": response}

# ê·¸ë˜í”„ êµ¬ì„± í•¨ìˆ˜
def create_chat_workflow() -> StateGraph:
    """ì±—ë´‡ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
    # ìƒíƒœ ê·¸ë˜í”„ ìƒì„±
    workflow = StateGraph(ChatState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("process_input", process_input)
    workflow.add_node("generate_llm_response", generate_llm_response)
    workflow.add_node("update_messages", update_messages)
    workflow.add_node("create_dashboard", create_dashboard_response)
    workflow.add_node("handle_error", handle_error)
    
    # ì—ì§€ ì¶”ê°€ (ì¡°ê±´ë¶€ ë¼ìš°íŒ…)
    
    # í”„ë¡œì„¸ìŠ¤ ì…ë ¥ í›„ ëŒ€ì‹œë³´ë“œ ëª¨ë“œ ë˜ëŠ” ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ì— ë”°ë¼ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "process_input",
        lambda state: "handle_error" if state.get("error") else
                     "create_dashboard" if state.get("dashboard_mode") else
                     "generate_llm_response"
    )
    
    # LLM ì‘ë‹µ ìƒì„± í›„ ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ì— ë”°ë¼ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "generate_llm_response",
        lambda state: "handle_error" if state.get("error") else "update_messages"
    )
    
    # ë‚˜ë¨¸ì§€ ì—ì§€ ì—°ê²°
    workflow.add_edge("update_messages", END)
    workflow.add_edge("create_dashboard", END)
    workflow.add_edge("handle_error", END)
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("process_input")
    
    return workflow

# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì»´íŒŒì¼
chat_workflow = create_chat_workflow()
chat_chain = chat_workflow.compile()

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜
def process_message(message: str, history: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:
    """ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜
    
    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        history: ì´ì „ ëŒ€í™” ì´ë ¥ (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ (ë©”ì‹œì§€, ì‘ë‹µ, ì´ë¯¸ì§€ ë“±)
    """
    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    state = create_initial_state()
    
    # ì´ì „ ì´ë ¥ ì„¤ì •
    state["messages"] = history or []
    
    # í˜„ì¬ ë©”ì‹œì§€ ì„¤ì •
    state["current_input"] = message
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = chat_chain.invoke(state)
    
    return result 